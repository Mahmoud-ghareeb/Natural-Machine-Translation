{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "83efKPiXd1KG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Following the Extract-Transform-Load pattern\n",
        "1. i will extract the data into tf.data.Dataset class\n",
        "2. perform some preprocessing/transformation on the data\n",
        "3. load the data into the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the 2 tokenizers en and sp\n",
        "1. because the data is small and fit in memmory i will loop throw the file and make 2 list en and sp\n",
        "2. adapt the en_vect on the en data and adapt the sp_tokenizer on the sp data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "created a class to read, clean and tokenize the text data and return train_dataset, val_dataset, input_tok and target_tok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rmUF2GLt8EnN"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "import unicodedata\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class MTM:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "\n",
        "  def unicode_to_ascii(self, s):\n",
        "    ''' unicode string '''\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "  def preprocess_sentence(self, s):\n",
        "    ''' \n",
        "        unicode sentence to ascii \n",
        "        keep any character and .?!,¿ punctiuations\n",
        "        add space between punctiuation and words for decoding\n",
        "        adding [SOS] and [EOS] special tokens\n",
        "    '''\n",
        "    s = self.unicode_to_ascii(s.lower().strip())\n",
        "    \n",
        "    s = re.sub(r'[^ a-z.?!,¿]', '', s)\n",
        "    s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "    s = re.sub(r'[\" \"]+', \" \", s)\n",
        "    \n",
        "    return '[SOS] ' + s + ' [EOS]'\n",
        "\n",
        "  def tokenize(self, data, seq_len):\n",
        "    vect = TextVectorization(standardize=None, output_sequence_length=seq_len)\n",
        "    vect.adapt(data)\n",
        "\n",
        "    return vect\n",
        "\n",
        "  def create_dataset(self, texts, in_targets, ot_targets):\n",
        "    return tf.data.Dataset.from_tensor_slices(((texts, in_targets), ot_targets))\n",
        "\n",
        "  def read_data(self, path):\n",
        "    inputs = []\n",
        "    targets = []\n",
        "    with open(path) as f:\n",
        "      for line in f.readlines():\n",
        "        line = line.split('\\t')\n",
        "        inputs.append(self.preprocess_sentence(line[1]))\n",
        "        targets.append(self.preprocess_sentence(line[0]))\n",
        "\n",
        "    max_inputs_length = max(len(x.split()) for x in inputs)\n",
        "    max_targets_length = max(len(x.split()) for x in targets)\n",
        "    \n",
        "    return inputs, targets, max_inputs_length, max_targets_length\n",
        "\n",
        "  def call(self, path):\n",
        "    inputs, targets, max_inputs_length, max_targets_length = self.read_data(path)\n",
        "    \n",
        "    input_vect = self.tokenize(inputs, max_inputs_length)\n",
        "    target_vect = self.tokenize(targets, max_targets_length)\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(inputs, targets)\n",
        "  \n",
        "    train_sp = x_train\n",
        "    train_en_inputs = [' '.join(seq.split()[:-1]) for seq in y_train]\n",
        "    train_en_outputs = [' '.join(seq.split()[1:]) for seq in y_train]\n",
        "\n",
        "    val_sp = x_val\n",
        "    val_en_inputs = [' '.join(seq.split()[:-1]) for seq in y_val]\n",
        "    val_en_outputs = [' '.join(seq.split()[1:]) for seq in y_val]\n",
        "\n",
        "    train_dataset = self.create_dataset(train_sp, train_en_inputs, train_en_outputs)\n",
        "    val_dataset = self.create_dataset(val_sp, val_en_inputs, val_en_outputs)\n",
        "\n",
        "    return train_dataset, val_dataset, input_vect, target_vect\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMKbOzpIII7n",
        "outputId": "32c2d580-0b2f-4d40-defb-9327b065630f"
      },
      "outputs": [],
      "source": [
        "##\n",
        "BATCH_SIZE = 16\n",
        "##\n",
        "\n",
        "mtm = MTM('spa-en')\n",
        "train_dataset, val_dataset, input_vect, target_vect = mtm.call('./data/spa.txt')\n",
        "\n",
        "def vectorize(x, y):\n",
        "    a, b = x\n",
        "    return (input_vect(a), target_vect(b)), target_vect(y)\n",
        "\n",
        "train_dataset = train_dataset.map(vectorize) \\\n",
        "                             .batch(BATCH_SIZE) \\\n",
        "                             .prefetch(BATCH_SIZE) \\\n",
        "                             .cache()\n",
        "\n",
        "val_dataset = val_dataset.map(vectorize) \\\n",
        "                             .batch(BATCH_SIZE) \\\n",
        "                             .prefetch(BATCH_SIZE) \\\n",
        "                             .cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV8d1r613IDq",
        "outputId": "68a4aac0-76d9-46d4-accf-9d2abbbd897a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[    2   113   445    14    43  2744    31 24704     4     3     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0], shape=(80,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[   2    6  550   12  104 1008    7 1058    4    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(82,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[   6  550   12  104 1008    7 1058    4    3    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(82,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for (sp, en_inputs), en_labels in train_dataset.take(1):\n",
        "  break\n",
        "print(sp[0])\n",
        "print(en_inputs[0])\n",
        "print(en_labels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CiQ4JTVEBQz"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transformers known for their parallel computing unlike RNNs but the position of the words is missing\n",
        "to solve this problem the authers of the paper \"Attention is all you need\" offers a fixed absolute position method called Position Embeddings.\n",
        "The idea is that we generate a fixed vector of the same size as the input sentence of shape (batch, seq_length, dim) and add it the the embedding of the sentence to encode the postion information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So\n",
        "1. make a configuration class\n",
        "2. import the model\n",
        "3. prepare the data\n",
        "4. train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    n_layers: int = 6\n",
        "    input_vocab_size: int = None\n",
        "    target_vocab_size: int = None\n",
        "    d_model: int = 300\n",
        "    num_heads: int = 8\n",
        "    ffd_units: int = 256\n",
        "    dropout: float = .3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZFcTmo-seGs",
        "outputId": "e2c09061-d421-47ee-d129-968ee65f5f99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([16, 82, 14163])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from model import Transformer\n",
        "\n",
        "config = Config()\n",
        "\n",
        "input_vocab_size=len(input_vect.get_vocabulary())\n",
        "target_vocab_size=len(target_vect.get_vocabulary())\n",
        "\n",
        "config.input_vocab_size = input_vocab_size\n",
        "config.target_vocab_size = target_vocab_size\n",
        "\n",
        "model = Transformer(config)\n",
        "\n",
        "model((sp, en_inputs)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43r_ucJvteLd",
        "outputId": "fb557115-aa23-4cf0-c44a-8e62a9fca38c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  26259036  \n",
            "                                                                 \n",
            " decoder (Decoder)           multiple                  39834636  \n",
            "                                                                 \n",
            " dense_24 (Dense)            multiple                  4263063   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 70,356,735\n",
            "Trainable params: 70,356,735\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        'd_model': self.d_model,\n",
        "        'warmup_steps': self.warmup_steps\n",
        "    }\n",
        "    return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GKGAcun9zuGm"
      },
      "outputs": [],
      "source": [
        "def masked_loss(label, pred):\n",
        "  mask = label != 0\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "  loss = loss_object(label, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  match = label == pred\n",
        "\n",
        "  mask = label != 0\n",
        "\n",
        "  match = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QjD4s5BSzyrG"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(config.d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "model.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Sp-5NgQyBmum"
      },
      "outputs": [],
      "source": [
        "# path = './checkpoints'\n",
        "# checkpoints = tensorflow.keras.callbacks.ModelCheckpoint(path, save_best_only=True)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(patience=1)\n",
        "# tensorboard = tensorflow.keras.callbacks.TensorBoard('./logs')\n",
        "# lrONplateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "#                                             monitor=\"val_loss\",\n",
        "#                                             factor=0.5,\n",
        "#                                             patience=1,\n",
        "#                                             min_lr=0.000001\n",
        "#                                          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgtQJjYxJHRj",
        "outputId": "da2f09f9-d613-4d8f-fef6-9a13dc0d036d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26673\n",
            "14163\n"
          ]
        }
      ],
      "source": [
        "print(input_vocab_size)\n",
        "print(target_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZKCg3hbz1SQ",
        "outputId": "527b3000-7d69-4376-f198-efb6c1df34f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6549/6549 [==============================] - 1225s 186ms/step - loss: 0.7964 - acc: 0.9074 - val_loss: 1.2869 - val_acc: 0.8990\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1f1744a6d00>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_dataset,\n",
        "          epochs=1, \n",
        "          validation_data=val_dataset,\n",
        "          callbacks=[earlystopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "o3-u2rrAnUrm"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as positional_embedding_layer_call_fn, positional_embedding_layer_call_and_return_conditional_losses, positional_embedding_1_layer_call_fn, positional_embedding_1_layer_call_and_return_conditional_losses, embedding_layer_call_fn while saving (showing 5 of 464). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
          ]
        }
      ],
      "source": [
        "### END OF THE MODEL\n",
        "\n",
        "tf.saved_model.save(model, './saved_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save_weights('./weights/model_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./text vectorizer/input_vectorizer\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./text vectorizer/input_vectorizer\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./text vectorizer/target_vectorizer\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./text vectorizer/target_vectorizer\\assets\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "input_vect = Sequential([input_vect])\n",
        "input_vect.save('./text vectorizer/input_vectorizer', save_format='tf')\n",
        "\n",
        "target_vect = Sequential([target_vect])\n",
        "target_vect.save('./text vectorizer/target_vectorizer', save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = input_vect.layers[0].layers[0].layers[0].get_vocabulary()\n",
        "\n",
        "with open('./vocabulary/vocab.txt', 'w', encoding='utf-8') as f:\n",
        "    for v in vocab:\n",
        "        f.write(v + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
